{
  "0": {
    "id": "0",
    "title": "Announcements",
    "content": "Announcements Announcements are stored in the _announcements directory and rendered according to the layout file, _layouts/announcement.html. Week 0 Announcements Welcome to Data 100! We’re still getting this site set up. Some information here may be inaccurate. We will remove this warning once the site is complete. Announcements We will not be updating this page with announcements. For the latest announcements, make sure to check our Piazza.",
    "url": "http://localhost:4000/su20/announcements/",
    "relUrl": "/announcements/"
  },
  "1": {
    "id": "1",
    "title": "Calendar",
    "content": "Calendar Live Lecture, Discussion, and Lab Calendar Office Hours Calendar Live Lecture, Discussion, and Lab Calendar This calendar contains times for live lecture recap sessions (in green) live discussion sessions (in red) and exam prep sessions (in orange) live lab sessions (in blue) other special events (in yellow) To access these events, use the Zoom links posted in @11 on Piazza. Office Hours Calendar GSI and tutor office hours are in grey. Click on each event to see which GSI or tutor is running each office hour time. You should come to these with questions about anything – labs, homeworks, projects, discussions, concepts, etc. To access GSI and tutor office hours, go to our Office Hours Queue. When it’s your turn, you will be given the Zoom link to join. Suraj and Allen’s office hours are in dark pink. You should come to these with questions about concepts and logistics. To access instructor office hours, use the Zoom links posted on Piazza.",
    "url": "http://localhost:4000/su20/calendar/",
    "relUrl": "/calendar/"
  },
  "2": {
    "id": "2",
    "title": "Final Project",
    "content": "Graduate Final Project Coming Soon",
    "url": "http://localhost:4000/su20/gradproject/",
    "relUrl": "/gradproject/"
  },
  "3": {
    "id": "3",
    "title": "Home",
    "content": "Principles and Techniques of Data Science UC Berkeley, Summer 2020 Suraj Rampure suraj.rampure@berkeley.edu Allen Shen allenshen5@berkeley.edu All announcements are on Piazza. Make sure you are enrolled and active there. The Syllabus contains a detailed explanation of how each course component will work this summer, given that the course is being taught entirely online. The scheduling of all weekly events is in the Calendar. Zoom links for live events: @11 on Piazza. Week 1 Jun 22 Lecture 1 Course Overview (slides) (video) (code) Ch. 1 Discussion 1 Prerequisite Review (video) (solutions) Homework 1 Prerequisites (due Jun. 24) Survey 1 Week 1 Survey (due Jun. 24) Jun 23 Lecture 2 Data Sampling and Probability Ch. 2 Lab 1 Prerequisite Coding (due Jun. 23) Jun 24 Lecture 3 Random Variables Ch. 12.1-12.2 Discussion 2 Random Variables (video) (solutions) Jun 25 Lecture 4 SQL Ch. 9 Homework 2 Trump Sampling (due Jun. 28) Lab 2 SQL (due Jun. 25) Jun 26 Live Session 1 Random Variables, SQL (video) (notes) Week 2 Jun 29 Lecture 5 Pandas I Ch. 3 Discussion 3 SQL (video) (solutions) Project 1 Food Safety (due Jul. 6) Survey 2 Week 2 Survey (due Jul. 1) Jun 30 Lecture 6 Pandas II Ch. 3 Lab 3 Pandas I (due Jun. 30) Jul 1 Lecture 7 Data Cleaning and EDA Ch. 4.1,Ch. 5 Discussion 4 Pandas II (video) (solutions) Jul 2 Lecture 8 Regular Expressions Ch. 8 Lab 4 Data Cleaning and EDA (due Jul. 2) Live Session 2 Pandas Demo (video) (code) (code HTML) Jul 3 N/A (Holiday) Week 3 Jul 6 Lecture 9 Visualization I Ch. 6.1-6.3 Discussion 5 Regex (video) (solutions) Homework 3 Bike Sharing (due Jul. 12) Survey 3 Week 3 Survey (due Jul. 8) Jul 7 Lecture 10 Visualization II Ch. 6.4-6.6 Lab 5 Transformations and KDEs (due Jul. 7) Jul 8 Lecture 11 Modeling Ch. 10 Discussion 6 Visualizations and Transformations Homework 4 Trump Jul 9 Exam Midterm 1 (7-8:30PM) Lab 6 Modeling and Loss Functions (due Jul. 12) Jul 10 Live Session 3 Lecture Recap (12-1PM) Week 4 Jul 13 Lecture 12 Simple Linear Regression Ch. 13.1-13.3 Discussion 7 Correlation Jul 14 Lecture 13 Ordinary Least Squares Ch. 13.4 Lab 7 Regression Jul 15 Lecture 14 Feature Engineering Ch. 14 Discussion 8 Geometric Least Squares &amp; One Hot Encoding Jul 16 Lecture 15 Bias-Variance Tradeoff Ch. 12.3, Ch. 15.1-15.2 Homework 5 Regression Lab 8 Feature Engineering Jul 17 Live Session 4 Lecture Recap (12-1PM) Week 5 Jul 20 Lecture 16 Regularization &amp; Cross-Validation Ch. 16, Ch. 15.3 Discussion 9 Bias Variance &amp; Cross Validation Homework 6 Housing Jul 21 Lecture 17 Gradient Descent Ch. 11 Lab 9 Cross Validation Jul 22 Lecture 18 Logistic Regression I Ch. 17.1-17.3 Discussion 10 Gradient Descent &amp; Logistic Regression Jul 23 Lecture 19 Logistic Regression II and Classification Ch. 17.4-17.7 Homework 7 Gradient Descent &amp; Logistic Regression Lab 10 Logistic Regression Jul 24 Live Session 5 Lecture Recap (12-1PM) Week 6 Jul 27 Exam Midterm 2 (7-8:30PM) Discussion 11 Cross Entropy Loss and Classification Jul 28 Lecture 20 Inference for Modeling Ch. 18.1, 18.3 Lab 11 Bootstrap the model parameters Jul 29 Lecture 21 Decision Trees Discussion 12 Decision Trees &amp; Random Forests Project 2 Spam/Ham Jul 30 Lecture 22 Dimensionality Reduction &amp; PCA Lab 12 Decision Trees Jul 31 Live Session 6 Lecture Recap (12-1PM) Week 7 Aug 3 Lecture 23 PCA Discussion 13 PCA Aug 4 Lecture 24 Clustering Lab 13 Clustering Aug 5 Lecture 25 Guest Lecture Discussion 14 Clustering Homework 8 PCA Aug 6 Lecture 26 Conclusion (live) Week 8 Aug 10 Lecture Review Aug 11 Lecture Review Aug 12 Exam Final Part 1 (7-8:30PM) Aug 13 Exam Final Part 2 (7-8:30PM)",
    "url": "http://localhost:4000/su20/",
    "relUrl": "/"
  },
  "4": {
    "id": "4",
    "title": "Lecture 10 – Visualization, Part 2",
    "content": "Lecture 10 – Visualization, Part 2 by Suraj Rampure (Summer 2020) slides video playlist code code HTML Extra reading on colormaps: How the Rainbow Color Map Misleads When to use Sequential and Diverging Palettes Color Use Guidelines Make sure to complete the Quick Check questions in between each video. These are ungraded, but it’s in your best interest to do them. Video Quick Check 10.1 Ensuring that the axes in our visualizations aren&#39;t misleading. 10.1 10.2 Designing visualizations that are well-suited for making comparisons. 10.2 10.3 How to use color to create effective visualizations. How to choose color schemes that are clear and accessible. 10.3 10.4 How to choose markings that the human eye can easily interpret. Issues to avoid, such as jiggling baselines and overplotting. 10.4 10.5 Discussing the supplemental text that publication-ready plots need. 10.5 10.6 When to use smoothing. How kernel density estimates are created. Looking at various kernels. Understanding the impact of the bandwidth hyperparameter. 10.6 10.7 Discussing why we prefer linear relationships. Understanding how to &quot;reverse-engineer&quot; a linearized relationship to determine the true relationship. Identifying which transformations to use in order to linearize a relationship. 10.7",
    "url": "http://localhost:4000/su20/lecture/lec10/",
    "relUrl": "/lecture/lec10/"
  },
  "5": {
    "id": "5",
    "title": "Lecture 11 – Introduction to Modeling",
    "content": "Lecture 11 – Introduction to Modeling by Suraj Rampure (Summer 2020) slides video playlist code code HTML Make sure to complete the Quick Check questions in between each video. These are ungraded, but it’s in your best interest to do them. Video Quick Check 11.1 Motivating examples of models. 11.1 11.2 Defining the constant model. Formalizing the notion of a parameter. 11.2 11.3 Loss functions and their purpose. Squared loss and absolute loss. Minimizing average loss (i.e. empirical risk). 11.3 11.4 Minimizing mean squared error for the constant model using calculus, to show that the sample mean is the optimal model parameter in this case. 11.4 11.5 Performing the same optimization as in the last video, but by using a non-calculus algebraic manipulation. 11.5 11.6 Minimizing mean absolute error for the constant model using calculus, to show that the sample median is the optimal parameter in this case. Identifying that this solution isn&#39;t necessarily unique. 11.6 11.7 Comparing the loss surfaces of MSE and MAE for the constant model. Discussing the benefits and drawbacks of squared and absolute loss. Recapping the &quot;modeling process&quot;. 11.7",
    "url": "http://localhost:4000/su20/lecture/lec11/",
    "relUrl": "/lecture/lec11/"
  },
  "6": {
    "id": "6",
    "title": "Lecture 2 – Data Sampling and Probability",
    "content": "Lecture 2 – Data Sampling and Probability by Suraj Rampure (Summer 2020) slides video playlist This is the first lecture of a brand-new format! Make sure to complete the Quick Check problems as you progress through the videos to confirm your understanding. Video Quick Check 2.1 Censuses and surveys. Issues with the US Census. 2.1 2.2 Samples. Drawbacks to convenience and quota samples. 2.2 2.3 A case study in sampling bias (1936 election). 2.3 2.4 Sources of bias, and a formal definition of sampling frames. 2.4 2.5 Probability samples, and why we need them. 2.5 2.6 Introducing binomial and multinomial probability calculations. 2.6 2.7 Generalizing binomial and trinomial probability calculations. 2.7 2.8 (Extra) Using permutations and combinations to derive the binomial coefficient. 2.8 2.9 (Extra) Example usages of the binomial coefficient. 2.9",
    "url": "http://localhost:4000/su20/lecture/lec2/",
    "relUrl": "/lecture/lec2/"
  },
  "7": {
    "id": "7",
    "title": "Lecture 3 – Random Variables",
    "content": "Lecture 3 – Random Variables by Suraj Rampure (Summer 2020) slides video playlist Lecture Recap 1, Part 1 (video) (notes) Make sure to complete the Quick Check questions in between each video. These are ungraded, but it’s in your best interest to do them. Video Quick Check 3.1 Formal definition of random variables. 3.1 3.2 Distributions of random variables. 3.2 3.3 Defining the Bernoulli and binomial distributions. (Stat 88 reading) 3.3 3.4 Discussing equality of random variables – equal vs. equal in distribution. 3.4 3.5 Expectation. Linearity of expectation. Sample calculations, and the expectation of the Bernoulli and binomial distributions. 3.5 3.6 Variance of random variables. Walking through an alternate calculation of variance. Variance of a linear transformation. 3.6 3.7 Deriving the variance of a sum. Understanding covariance, correlation, and independence. 3.7 3.8 Variance of an i.i.d. sum. Variance of the Bernoulli and binomial distributions. 3.8 3.9 Variability of the sample mean. Reviewing inferential concepts from Data 8, but with the framework of random variables. 3.9",
    "url": "http://localhost:4000/su20/lecture/lec3/",
    "relUrl": "/lecture/lec3/"
  },
  "8": {
    "id": "8",
    "title": "Lecture 4 – SQL",
    "content": "Lecture 4 - SQL by Allen Shen (Summer 2020) slides video playlist code code HTML code walkthrough (Josh Hug) code walkthrough (Allen Shen) Make sure to complete the Quick Check questions in between each video. These are ungraded, but it’s in your best interest to do them. Video Quick Check 4.1 Databases and database management systems. 4.1 4.2 Relational database schemas. 4.2 4.3 SQL overview and the DISTINCT keyword. 4.3 4.4 Types of joins in SQL. 4.4 4.5 NULL values in SQL. 4.5 4.6 SQL predicates and casting. 4.6 4.7 SQL sampling, subqueries, and common table expressions. 4.7 4.8 SQL CASE expressions and the SUBSTR function. 4.8 4.9 SQL summary and conclusion. 4.9 Notebook Notebook walkthrough (Josh Hug). N/A Notebook Notebook walkthrough (Allen Shen). N/A",
    "url": "http://localhost:4000/su20/lecture/lec4/",
    "relUrl": "/lecture/lec4/"
  },
  "9": {
    "id": "9",
    "title": "Lecture 5 – Pandas, Part 1",
    "content": "Lecture 5 - Pandas, Part 1 by Josh Hug (Fall 2019) slides video playlist code code HTML Intro to Pandas if you’ve taken Data 8 (zip) Make sure to complete the Quick Check questions in between each video. These are ungraded, but it’s in your best interest to do them. Video Quick Check 5.1.1 Pandas data frames, series, and indices. 5.1.1 5.1.2 Pandas indices demo. 5.1.2 5.2 Pandas indexing with the bracket operator. 5.2 5.3 Pandas boolean array selection, the isin function, and the query command. 5.3 5.4.1 Pandas indexing with .loc. 5.4.1 5.4.2 Pandas indexing with .iloc and Pandas sampling. 5.4.2 5.5.1 Pandas utility functions, properties, and the sort_values method. 5.5.1 5.5.2 The value_counts and unique methods in Pandas. An exploration of the baby names data set. 5.5.2",
    "url": "http://localhost:4000/su20/lecture/lec5/",
    "relUrl": "/lecture/lec5/"
  },
  "10": {
    "id": "10",
    "title": "Lecture 6 – Pandas, Part 2",
    "content": "Lecture 6 - Pandas, Part 2 by Josh Hug (Fall 2019) slides video playlist code code HTML joins code HTML Make sure to complete the Quick Check questions in between each video. These are ungraded, but it’s in your best interest to do them. Video Quick Check 6.1 Pandas string methods. 6.1 6.2 Adding, modifying, and removing columns in Pandas. 6.2 6.3 Using the Pandas groupby function for aggregation. 6.3 6.4 Puzzles using the Pandas groupby function. 6.4 6.5 Other features of the Pandas groupby function including size and filter. 6.5 6.6 Grouping by multiple columns and pivot tables in Pandas. 6.6 6.7 Joining two tables in Pandas. 6.7",
    "url": "http://localhost:4000/su20/lecture/lec6/",
    "relUrl": "/lecture/lec6/"
  },
  "11": {
    "id": "11",
    "title": "Lecture 7 – Data Cleaning and EDA",
    "content": "Lecture 7 – Data Cleaning and EDA by Joseph Gonzalez (Spring 2020) slides video playlist code (bonus) Joe Hellerstein’s primer on data models Make sure to complete the Quick Check questions in between each video. These are ungraded, but it’s in your best interest to do them. Video Quick Check 7.1 Exploratory data analysis and its position in the data science lifecycle. The relationship between data cleaning and EDA. 7.1 7.2 Exploring various different data storage formats and their tradeoffs. 7.2 7.3 Primary keys and foreign keys. Eliminating redundancy in tables. 7.3 7.4 Defining and discussing the terms quantitative discrete, quantitative continuous, qualitative ordinal, qualitative nominal. 7.4 7.5 Discussing the granularity and scope of our data to ensure that it&#39;s appropriate for analysis. Discussing various methods of encoding time, and flaws to be aware of. 7.5 7.6 Ways in which our data can be incorrect or corrupt. Different methods for addressing missing values, and their tradeoffs. 7.6 7.7 Summarizing the process of EDA, and a demo of EDA on real data. 7.7",
    "url": "http://localhost:4000/su20/lecture/lec7/",
    "relUrl": "/lecture/lec7/"
  },
  "12": {
    "id": "12",
    "title": "Lecture 8 – Regular Expressions",
    "content": "Lecture 8 - Regular Expressions by Josh Hug (Fall 2019) slides video playlist code code HTML Make sure to complete the Quick Check questions in between each video. These are ungraded, but it’s in your best interest to do them. Video Quick Check 8.1 Canonicalizing strings and using the split method to extract from textual data. 8.1 8.2 Basic regular expression syntax (i.e. closures). Order of operations in regular expressions. 8.2 8.3 Expanded regular expression syntax (i.e. character classes). A couple of regular expression exercises. 8.3 8.4 Limitations of regular expressions. Other regular expression syntax (i.e. lazy closures). 8.4 8.5 Using regular expressions in Python. Regular expression groups. 8.5 8.6 Regular expression case studies on police data and restaurant data. 8.6",
    "url": "http://localhost:4000/su20/lecture/lec8/",
    "relUrl": "/lecture/lec8/"
  },
  "13": {
    "id": "13",
    "title": "Lecture 9 – Visualization, Part 1",
    "content": "Lecture 9 – Visualization, Part 1 by Suraj Rampure (Summer 2020) slides video playlist code code HTML Make sure to complete the Quick Check questions in between each video. These are ungraded, but it’s in your best interest to do them. Video Quick Check 9.1 Formal definition of visualization. The purpose of visualization in the data science lifecycle. 9.1 9.2 Different ways we can map from data to properties of a visualization. 9.2 9.3 Defining distributions, and determining whether or not given visualizations contain a distribution. 9.3 9.4 Bar plots as a means of displaying the distribution of a qualitative variable, as well as for plotting a quantitative variable across several different categories. 9.4 9.5 Rug plots. Histograms, where areas are proportions. Reviewing histogram calculations from Data 8. Density curves as smoothed versions of histograms. 9.5 9.6 Describing distributions of quantitative variables using terms such as modes, skew, tails, and outliers. 9.6 9.7 Using box plots and violin plots to visualize quantitative distributions. Using overlaid histograms and density curves, and side by side box plots and violin plots, to compare multiple quantitative distributions. 9.7 9.8 Using scatter plots, hex plots, and contour plots to visualize the relationship between pairs of quantitative variables. Summary of visualization thus far. 9.8",
    "url": "http://localhost:4000/su20/lecture/lec9/",
    "relUrl": "/lecture/lec9/"
  },
  "14": {
    "id": "14",
    "title": "Resources",
    "content": "Resources Exam Resources Semester Midterm 1 Midterm 2 Final Spring 2020 Checkpoint (Solutions)   N/A Fall 2019 Exam (Solutions) Exam (Solutions) Exam (Solutions) Summer 2019 Exam (Solutions) [Video]   Exam (Solutions) Spring 2019 Exam (Solutions) [Video] Exam (Solutions) [Video] Exam (Solutions) Fall 2018 Exam (Solutions)   Exam (Solutions) Spring 2018 Exam (Solutions)   Exam (Solutions) [Video] Fall 2017 Exam (Solutions) [Video]   Exam (Solutions) Spring 2017 Exam (Solutions)   Exam (Solutions) Spring 2020 Checkpoint Reference Sheet Fall 2019 Midterm 1 Reference Sheet Spring 2019 Midterm 1 Reference Sheet Other Resources We will be posting all lecture materials on the course syllabus. In addition, they will also be listed in the following publicly visible Github Repo. Here is a collection of resources that will help you learn more about various concepts and skills covered in the class. Learning by reading is a key part of being a well rounded data scientist. We will not assign mandatory reading but instead encourage you to look at these and other materials. If you find something helpful, post it on Piazza, and consider contributing it to the course website. You can send us changes to the course website by forking and sending a pull request to the course website github repository. You will then become part of the history of Data 100 at Berkeley. Local Setup Click here to read our guide on how to set up our development environment locally (as an alternative to using DataHub). SQL Resources We’ve assembled some SQL Review Slides to help you brush up on SQL. We’ve also compiled a list of SQL practice problems, which can be found here, along with their solutions. This SQL Cheat Sheet is an awesome resource that was created by Luke Harrison, a former Data 100 student. Probability Practice We’ve compiled a few practice probability problems that we believe may help in understanding the ideas covered in the course. They can be found here, along with their solutions. We’d also like to point you to the textbook for Stat 88, an introductory probability course geared towards data science students at Berkeley. Regex Practice We’ve organized some regex problems to help you get extra practice on regex in a notebook format. They can be found here, along with their solutions. Web References As a data scientist you will often need to search for information on various libraries and tools. In this class we will be using several key python libraries. Here are their documentation pages: The Bash Command Line: Linux and Bash: Intro to Linux, Cloud Computing (which you can skip for the purposes of this class), and the Bash command line. You can skip all portions that don’t pertain to using the command line. Bash Part 2: Part 2 of the intro to command line. Python: Python Tutorial: Teach yourself python. This is a pretty comprehensive tutorial. Python + Numpy Tutorial this tutorial provides a great overview of a lot of the functionality we will be using in DS100. Python 101: A notebook demonstrating a lot of python functionality with some (minimal explanation). Data Visualization: matplotlib.pyplot tutorial: This short tutorial provides an overview of the basic plotting utilities we will be using. Altair Documentation: Altair(Vega-Lite) is a new and powerful visualization library. We might not get to teach it this semester, but you should check it out if you are interested in pursuing visualization deeper. In particular, you should find the example gallery helpful. Prof. Jeff Heer’s Visualization Curriculum: This repository contains a series of Python-based Jupyter notebooks that teaches data visualization using Vega-Lite and Altair. If you are interested in learning more about data visualization, you can find more materials in: Edward Tufte’s book sequences – a classic! Prof. Heer’s class. Pandas: The Pandas Cookbook: This provides a nice overview of some of the basic Pandas functions. However, it is slightly out of date. Learn Pandas A set of lessons providing an overview of the Pandas library. Python for Data Science Another set of notebook demonstrating Pandas functionality. Books Because data science is a relatively new and rapidly evolving discipline there is no single ideal textbook for this subject. Instead we plan to use reading from a collection of books all of which are free. However, we have listed a few optional books that will provide additional context for those who are interested. Principles and Techniques of Data Science This is the accompanying textbook written for DS100 course. Introduction to Statistical Learning (Free online PDF) This book is a great reference for the machine learning and some of the statistics material in the class Data Science from Scratch (Available as eBook for Berkeley students) This more applied book covers many of the topics in this class using Python but doesn’t go into sufficient depth for some of the more mathematical material. Doing Data Science (Available as eBook for Berkeley students) This books provides a unique case-study view of data science but uses R and not Python. Python for Data Analysis (Available as eBook for Berkeley students). This book provides a good reference for the Pandas library. Data Science Education Interested in bringing the Data Science major or curriculum to your academic institution? Please fill out this form if you would like support from Berkeley in offering some variant of our Data Science courses at your institution (or just to let us know that you’re interested). Information about the courses appear at data8.org and ds100.org. Please note that this form is for instructors. If you are only interested in learning Python or data science, please look at our Data 8 or Data 100 websites mentioned above.",
    "url": "http://localhost:4000/su20/resources/",
    "relUrl": "/resources/"
  },
  "15": {
    "id": "15",
    "title": "Local Setup",
    "content": "Local Setup We will still be using datahub as our primary computing environment. This page serves as a guide for alternative environment setup. In other words: you don’t have to follow these instructions unless you’d like an alternative to datahub. Contents Installing conda by OS OSX Windows Linux Creating your environment Working on assignments locally Opening notebooks locally Verifying your environment Removing the environment to start over Submitting your work FAQ OSX You will need access to the command line. On a Mac, you can open the Terminal by opening Spotlight (Cmd + Space) and typing &quot;Terminal&quot;. Alternatively, you can go to your Applications screen and select Terminal (it might be in the folder named &quot;Other&quot;) Homebrew is a package manager for OSX. If you haven’t already, install it by running the following in the command line (copy, paste, and enter): # This downloads the Ruby code of the installation script and runs it /usr/bin/ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot; Verify your installation by making sure brew --version doesn’t error at your terminal. Download and install Anaconda: # Uses curl to download the installation script curl https://repo.continuum.io/miniconda/Miniconda2-4.5.11-MacOSX-x86_64.sh &gt; miniconda.sh # Run the miniconda installer (you will need to enter your password) bash miniconda.sh Close and restart your terminal. Ensure the installation worked by running conda --version. You may remove the miniconda.sh script now if you’d like. Click here to continue to the next part of the setup. Windows Windows is especially prone to error if you aren’t careful about your configuration. If you’ve already had Anaconda or git installed and can’t get the other to work, try uninstalling everything and starting from scratch. Installing Anaconda: Visit the Anaconda website and download the installer for Python 3.7. Download the 64-bit installer if your computer is 64-bit (most likely), the 32-bit installer if not. See this FAQ if you are unsure. Run the exe file to install Anaconda. Leave all the options as default (install for all users, in the default location). Make sure both of these checkboxes are checked: 1) Verify that the installation is working by starting the Anaconda Prompt (you should be able to start it from the Start Menu) and typing python: Notice how the python prompt shows that it is running from Anaconda. Now you have conda installed! From now on, when we talk about the “Terminal” or “Command Prompt”, we are referring to the Anaconda Prompt that you just installed. Click here to continue to the next part of the setup. Linux These instructions assume you have apt-get (Ubuntu and Debian). For other distributions of Linux, substitute the appropriate package manager. Your terminal program allows you to type commands to control your computer. On Linux, you can open the Terminal by going to the Applications menu and clicking “Terminal”. Install wget. This is a command-line tool that lets you download files / webpages at the command line. sudo apt-get install wget Download the Anaconda installation script: wget -O install_anaconda.sh https://repo.continuum.io/miniconda/Miniconda2-4.5.11-Linux-x86_64.sh 4) Install Anaconda: bash install_anaconda.sh 5) Close and restart your terminal. Ensure the installation worked by running `conda --version`. You may remove the install_anaconda.sh script now if you’d like. Click here to continue to the next part of the setup. Creating your environment These instructions are the same for OSX, Windows, and Linux. Download the data100 data100_environment.yml] from the course repository here or: # download via curl curl https://raw.githubusercontent.com/DS-100/su20/gh-pages/resources/assets/local_setup/data100_environment.yml &gt; data100_environment.yml # OR download via wget wget -O data100_environment.yml https://raw.githubusercontent.com/DS-100/su20/gh-pages/resources/assets/local_setup/data100_environment.yml This YAML file is what we use to specify the dependencies and packages (and their versions) we wish to install into the conda environment we will make for this class. The purpose of the environment is to ensure that everyone in the course is using the same package versions for every assignment whether or not they are working on datahub. This is to prevent inconsistent behavior due to differences in package versions. Using the Terminal, navigate to the directory where you downloaded data100_environment.yml. Run these commands to create a new conda environment. Each conda environment maintains its own package versions, allowing us to switch between package versions easily. For example, this class uses Python 3, but you might have another that uses Python 2. With a conda environment, you can switch between those at will. # sanity check on conda installation. Should be 4.5 or higher conda --version # update conda just in case it&#39;s out of date # enter y if prompted to proceed conda update conda # download git conda install -c anaconda git # Create a python 3.6 conda environment with the full set # of packages specified in environment.yml (jupyter, numpy, pandas, ...) conda env create -f data100_environment.yml # Switch to the data100 environment conda activate data100 # Check if packages are in the environment # This should not be empty! conda list From now on, you can switch to the data100 env with conda activate data100, and switch back to the default env with conda deactivate. Working on assignments locally These instructions are the same for OSX, Windows, and Linux. To work on assignments, you should fetch the assignment on datahub, navigate to the assignment folder and click on the download icon on the top right: Then you can unzip the files into a folder of your choosing. Remember the location of your assignment files because you’ll need to navigate to that folder to open the notebook. Opening notebooks locally To open Jupyter notebooks, you’ll navigate to parent directory of the assignment in your terminal, activate the environment, and start up a jupyter server. This will look something like: cd path/to/assignment/directory conda activate data100 jupyter notebook This will automatically open the notebook interface in your browser. You can then browse to a notebook and open it. Make sure to always work in the data100 conda environment when you are using jupyter notebooks for this class. This ensures you have all the necessary packages required for the notebook to run. Verifying Your Environment You can tell if you are correct environment if your terminal looks something like: Additionally, conda env list outputs a list of all your conda environments, and data100 should appear with a * next to it (the active one). Removing the environment to start over If you feel as if you’ve messed up and need to start over, you can remove the environment with conda remove --name data100 --all To verify that the environment was removed, in your Terminal window or an Anaconda Prompt, run: conda info --envs Which should then no longer display the data100 environment. Submitting your work Submissions will still be handled via datahub. To upload your work, navigate to the appropriate assignment folder on datahub and click on the upload button on the top right. Remember to validate, submit, and upload to Gradescope (for homeworks and projects). FAQ Shell not properly configured to use conda activate If you had an older version of Anaconda installed (perhaps for another class), you may see the following message. Follow the instructions in the prompt to: Enable conda for all users sudo ln -s ... Put the base environment on PATH echo &quot;conda activate&quot; &gt;&gt; ~/.bash_profile&quot;. Note that ~/.bash_profile may be something different like ~/.bashrc. Manually remove the line that looks like export PATH=&quot;/usr/local/miniconda3/bin:$PATH&quot; from your .bash_profile. Use your favorite plaintext editor to do this (do not use a rich text editor like Microsoft Word!).",
    "url": "http://localhost:4000/su20/setup/",
    "relUrl": "/setup/"
  },
  "16": {
    "id": "16",
    "title": "Staff",
    "content": "Staff Jump to Instructors, Teaching Assistants, or Tutors Note: Consult the calendar for the most up-to-date office hours for each GSI. Instructors {% assign instructors = site.staffers | where: &#39;role&#39;, &#39;Instructor&#39; %} {% for staffer in instructors %} {{ staffer }} {% endfor %} Teaching Assistants {% assign teaching_assistants = site.staffers | where: &#39;role&#39;, &#39;Teaching Assistant&#39; %} {% for staffer in teaching_assistants %} {{ staffer }} {% endfor %} Tutors {% assign readers = site.staffers | where: &#39;role&#39;, &#39;Tutor&#39; %} {% for staffer in readers %} {{ staffer }} {% endfor %}",
    "url": "http://localhost:4000/su20/staff/",
    "relUrl": "/staff/"
  },
  "17": {
    "id": "17",
    "title": "Syllabus",
    "content": "Syllabus Jump to: About Data 100 Online Format Policies About Data 100 Combining data, computation, and inferential thinking, data science is redefining how people and organizations solve challenging problems and understand their world. This intermediate level class bridges between Data8 and upper division computer science and statistics courses as well as methods courses in other fields. In this class, we explore key areas of data science including question formulation, data collection and cleaning, visualization, statistical inference, predictive modeling, and decision making.​ Through a strong emphasis on data centric computing, quantitative critical thinking, and exploratory data analysis, this class covers key principles and techniques of data science. These include languages for transforming, querying and analyzing data; algorithms for machine learning methods including regression, classification and clustering; principles behind creating informative data visualizations; statistical concepts of measurement error and prediction; and techniques for scalable data processing. Goals Prepare students for advanced Berkeley courses in data-management, machine learning, and statistics, by providing the necessary foundation and context Enable students to start careers as data scientists by providing experience working with real-world data, tools, and techniques Empower students to apply computational and inferential thinking to address real-world problems Prerequisites While we are working to make this class widely accessible, we currently require the following (or equivalent) prerequisites. We are not enforcing prerequisites during enrollment. However, all of the prerequisties will be used starting very early on in the class. It is your responsibility to know the material in the prerequisites.: Foundations of Data Science: Data8 covers much of the material in Data 100 but at an introductory level. Data8 provides basic exposure to python programming and working with tabular data as well as visualization, statistics, and machine learning. Computing: The Structure and Interpretation of Computer Programs (CS 61A) or Computational Structures in Data Science (CS 88). These courses provide additional background in python programming (e.g., for loops, lambdas, debugging, and complexity) that will enable Data 100 to focus more on the concepts in Data Science and less on the details of programming in python. Math: Linear Algebra (Math 54, EE 16a, or Stat89a): We will need some basic concepts like linear operators, eigenvectors, derivatives, and integrals to enable statistical inference and derive new prediction algorithms. This may be satisfied concurrently to Data 100. Online Format This summer, Data 100 will be run entirely online. This section details exactly how each component of the course will operate. To see when any live events are scheduled, check the Calendar. To see when lectures, discussions, and assignments are released (and due), check the Home Page. Lecture There are 4 lectures per week over the summer. Lectures will be entirely pre-recorded, in a format that is optimized for online learning (short 5-10 minute videos with conceptual problems in between). Lecture videos will be released on the mornings of Monday, Tuesday, Wednesday, and Thursday (or the night before). Some of these will be from previous semesters, and some will be recorded this summer by the instructors. Lecture videos will be posted on YouTube. Each “lecture” will be an html page linked on the course website, containing videos and links to slides and code. There are “Quick Check” conceptual questions in between each lecture video, linked on the lecture webpage. These are meant for you to check your understanding of the concepts that were just introduced. These are not graded. Each lecture will also have a Piazza thread for students to ask questions. In order to facilitate some interaction, instructors will be holding one live “lecture recap” per week. It will be an hour long, hosted via Zoom on Fridays from 12-1PM (and will be recorded). Most notably, we will not introduce new concepts in these recap sessions; instead, they’ll consist of: Answering students’ questions. Going over challenging problems (past exam problems, or more generally forcing students to push outside of what they’ve already learned). Other high-level overviews as deemed necessary. The instructors will also be hosting several conceptual office hours per week. See the Calendar for more details. Some special lectures will be live (such as the first lecture, last lecture, and any guest lectures). Specifics will be on Piazza. Note: Alongside each lecture are textbook readings. Textbook readings are purely supplementary, and may contain material that is not in scope (and may also not be comprehensive). Homeworks and Projects Homeworks are half-week long assignments that are designed to help students develop an in-depth understanding of both the theoretical and practical aspects of ideas presented in lecture. Projects are week-long assignments that integrate these ideas with real-world datasets. Each week, there are two homework assignments due. One homework will come out Sunday morning and will be due Wednesday night. The other will come out Thursday morning and will be due Sunday night. In some weeks, there will be a single long project instead of two homeworks. In total, there will be 8 homeworks and 2 projects. During midterm weeks, students will have a week to work on a homework (that they’d otherwise have half a week to work on). Two homeworks will be on-paper written assignments; the rest will be Jupyter notebooks. The primary form of support students will have for homeworks and projects are the office hours we’ll host, and Piazza. Labs Labs are shorter programming assignments designed to give students familiarity with new ideas. Each week, there are two lab assignments due. One lab will come out Monday morning and will be due Tuesday night. The other will come out Wednesday morning and will be due Thursday night. The primary form of support students will have for labs are the office hours we’ll host, and Piazza. We are also experimenting with a live lab section, in which GSIs walk through the lab assignment via Zoom. The current plan is to host one of these for each lab assignment (one on Tuesday, one on Thursday); see the Calendar for when these are scheduled. Discussions Discussion sections are meant to allow students a chance to discuss conceptual ideas and solve problems with other students, with the help of a GSI (this becomes slightly harder given the fact that this course is being offered completely remotely). Each discussion consists of a worksheet. Each week, there are two discussion worksheets. The first discussion will come out on Monday morning. The other will come out on Wednesday morning. There are two “pathways” we envision students taking when it comes to consuming discussion content. Watching a pre-recorded discussion video, and coming to a discussion recap section. Each discussion worksheet will be accompanied with a GSI-created video walkthrough, released at the same time. Students should watch this video soon after it is released. Then, students should come to the “discussion recap”, held on Monday afternoon for the first discussion and Wednesday afternoon for the second discussion (one each). The goal of these is to finish answering questions in the videos, and to serve as conceptual office hours for those concepts. Coming to a live Zoom discussion section. There will be three live Zoom discussions on Monday (morning, afternoon, night) and three on Wednesday, for the first and second discussions of the week, respectively. GSIs will host these in pairs and take turns rotating through. Each week, we will survey students on which of the two pathways they utilized and think is helpful, and will scale our resources accordingly. Office Hours We plan on hosting roughly 10 hours of office hours each weekday. These hours are listed on the Calendar. OH will serve as a one-stop shop for students to get help with assignments. Notably, they also serve as a replacement for traditional lab sessions. Office Hours can be accessed via oh.ds100.org, where students add themselves to the “queue” and specify the assignment they need help on. Once it’s their turn, they will be provided with a Zoom link to join, in order to get help from staff. The instructors will also be hosting conceptual office hours. These will be reflected on the Calendar. Exams There will be two midterm exams, and a final exam. Details about dates can be found in the policies section below. Policies Scores in the course are assigned according to the following weights: Category Weight Details Homeworks 28% 4% each (8, with 1 drop) Labs 10% 1% each (14, with 4 drops) Surveys 2% 0.25% each (8, with 0 drops) Projects 12% 6% each (2, with 0 drops) Midterm 1 12%   Midterm 2 12%   Final 24% two days, 12% each day Assignments Homeworks: Homeworks are usually assigned twice every week (see Projects below). They must be completed individually and will mix programming and short-answer questions. Homeworks have both visible and hidden autograder tests. The visible tests are mainly sanity checks, e.g. a probability is &lt;= 1, and are visible to students while they do the assignment. The hidden tests generally check for correctness, and are invisible to students while they are doing the assignment. Your lowest homework score will be dropped. Labs: Labs are assignments that complement the homeworks. There will be two lab assignments every week. All lab autograder tests are visible. Your four lowest lab scores will be dropped. Surveys: Weekly check-ins to gauge and receive student feedback, via Google Forms. Projects: Projects are week-long assignments that synthesize multiple topics. Exams Midterms: There will be two midterms. Midterm 1: Thursday, July 9th, 7-8:30PM PDT. Midterm 2: Monday, July 27th, 7-8:30PM PDT. Alternate exams will only be given to students with a documented conflict, or to those who are in timezones where 7-8:30PM PDT is extremely inconvenient. Final: We are currently planning on having a two-day final, held on Wednesday, August 12th and Thursday, August 13th, from 7-8:30PM PDT on both days. Each day will consist of a separate 1.5 hour exam. We may switch to a more traditional one day, 3 hour exam on Thursday, August 13th from 6-9PM PDT. We intend on using Zoom to proctor students during the final exam. Late Policy All assignments are due at 11:59 pm on the due date specified on the syllabus. Extensions are only provided to students with DSP accommodations, or in the case of exceptional circumstances. Homeworks and labs will not be accepted late. Gradescope may allow you to make late submissions, but you will later be given a 0. Projects are marked down by 10% per day, up to two days. After two days, project submissions will not be accepted. Submission times are rounded up to the next day. That is, 2 minutes late = 1 day late. Collaboration Policy and Academic Dishonesty Assignments Data science is a collaborative activity. While you may talk with others about the homework, we ask that you write your solutions individually in your own words. If you do discuss the assignments with others please include their names at the top of your notebook. Keep in mind that content from assignments will likely be covered on both the midterm and final. If we suspect that you have submitted plagiarized work, we will call you in for a meeting. If we then determine that plagiarism has occurred, we reserve the right to give you a negative full score (-100%) or lower on the assignments in question, along with reporting your offense to the Center of Student Conduct. Rather than copying someone else’s work, ask for help. You are not alone in this course! The entire staff is here to help you succeed. If you invest the time to learn the material and complete the assignments, you won’t need to copy any answers. (taken from 61A) Exams Cheating on exams is a serious offense. We have methods of detecting cheating on exams – so don’t do it! Students caught cheating on any exam will fail this course. We will be following the EECS departmental policy on Academic Honesty, so be sure you are familiar with it. We want you to succeed! If you are feeling overwhelmed, visit our office hours and talk with us. We know college can be stressful – and especially so during the COVID-19 pandemic – and we want to help you succeed.",
    "url": "http://localhost:4000/su20/syllabus/",
    "relUrl": "/syllabus/"
  }
  
}
